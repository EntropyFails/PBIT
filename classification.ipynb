{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ml packages\n",
    "\n",
    "import string\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn.model_selection as model_selection\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import (CountVectorizer, HashingVectorizer, TfidfVectorizer)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.decomposition import PCA, TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"./train.csv/train.csv\")\n",
    "test_df = pd.read_csv(\"./test.csv/test.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a preprocessing class\n",
    "class Preprocessor:\n",
    "    def __init__(self, df) -> None:\n",
    "        self.df = df\n",
    "\n",
    "    # convert all charecters to lower case\n",
    "    def convertToLower(self):\n",
    "        self.df[\"comment_text\"] = self.df[\"comment_text\"].apply(lambda x: x.lower())\n",
    "        return self.df\n",
    "\n",
    "    # remove stop words\n",
    "    def removeStopWords(self):\n",
    "        stop = stopwords.words(\"english\")\n",
    "        self.df[\"comment_text\"] = self.df[\"comment_text\"].apply(\n",
    "            lambda x: \" \".join([word for word in x.split() if word not in stop])\n",
    "        )\n",
    "        return self.df\n",
    "\n",
    "    # remove punctuation\n",
    "    def removePunctuation(self):\n",
    "        self.df[\"comment_text\"] = self.df[\"comment_text\"].str.replace(\"[^\\w\\s]\", \"\")\n",
    "        return self.df\n",
    "\n",
    "    # remove numbers\n",
    "    def removeNumbers(self):\n",
    "        self.df[\"comment_text\"] = self.df[\"comment_text\"].str.replace(\"[0-9]\", \"\")\n",
    "        return self.df\n",
    "\n",
    "    # remove whitespaces\n",
    "    def removeWhitespaces(self):\n",
    "        self.df[\"comment_text\"] = self.df[\"comment_text\"].apply(\n",
    "            lambda x: \" \".join(x.split())\n",
    "        )\n",
    "        return self.df\n",
    "\n",
    "    # remove urls\n",
    "    def removeURLs(self):\n",
    "        self.df[\"comment_text\"] = self.df[\"comment_text\"].str.replace(\n",
    "            \"https?://\\S+|www\\.\\S+\", \"\"\n",
    "        )\n",
    "        return self.df\n",
    "\n",
    "    # snowball stemmer algorithm\n",
    "    def snowballstemmer(self):\n",
    "        stemmer = SnowballStemmer()\n",
    "\n",
    "        def stem_words(text):\n",
    "            return \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "\n",
    "        self.df[\"comment_text\"] = self.df[\"comment_text\"].apply(\n",
    "            lambda x: stem_words(x)\n",
    "        )\n",
    "        return self.df\n",
    "\n",
    "    # port stemmer algorithm\n",
    "    def porterstemmer(self):\n",
    "        stemmer = PorterStemmer()\n",
    "\n",
    "        def stem_words(text):\n",
    "            return \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "\n",
    "        self.df[\"comment_text\"] = self.df[\"comment_text\"].apply(\n",
    "            lambda x: stem_words(x)\n",
    "        )\n",
    "        return self.df\n",
    "\n",
    "    # lemmatizing\n",
    "    def lemmatize(self):\n",
    "        from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "        def lemmatize_words(text):\n",
    "            return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "\n",
    "        self.df[\"comment_text\"] = self.df[\"comment_text\"].apply(\n",
    "            lambda x: lemmatize_words(x)\n",
    "        )\n",
    "        return self.df\n",
    "\n",
    "    # remove id and index columns\n",
    "    def removeUnwantedCols(self, col):\n",
    "        print(self.df.shape)\n",
    "        self.df = self.df.drop(col, axis=1)\n",
    "        return self.df\n",
    "\n",
    "    # word tokenization using nltk\n",
    "    def wordTokenization(self):\n",
    "        self.df[\"comment_text\"] = self.df[\"comment_text\"].apply(\n",
    "            lambda x: nltk.word_tokenize(x)\n",
    "        )\n",
    "        return self.df\n",
    "        \n",
    "\n",
    "    def preprocess(self):\n",
    "        # self.df = self.convertToLower()\n",
    "        # self.df = self.removeStopWords()\n",
    "        # self.df = self.removePunctuation()\n",
    "        # self.df = self.removeNumbers()\n",
    "        # self.df = self.removeURLs()\n",
    "        # self.df = self.removeWhitespaces()\n",
    "        # self.df = self.snowballstemmer()\n",
    "        # self.df = self.porterstemmer()\n",
    "        # self.df = self.lemmatize()\n",
    "        # self.df = self.wordTokenization()\n",
    "        self.df = self.removeUnwantedCols([\"id\"])\n",
    "        # self.df = self.removeUnwantedCols([\"toxic\"])\n",
    "        # self.df = self.removeUnwantedCols([\"severe_toxic\"])\n",
    "        # self.df = self.removeUnwantedCols([\"obscene\"])\n",
    "        # self.df = self.removeUnwantedCols([\"threat\"])\n",
    "        # self.df = self.removeUnwantedCols([\"insult\"])\n",
    "\n",
    "        # print(self.df.head())\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  toxic  severe_toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0             0   \n",
       "1  D'aww! He matches this background colour I'm s...      0             0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0             0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0             0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0             0   \n",
       "\n",
       "   obscene  threat  insult  identity_hate  \n",
       "0        0       0       0              0  \n",
       "1        0       0       0              0  \n",
       "2        0       0       0              0  \n",
       "3        0       0       0              0  \n",
       "4        0       0       0              0  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproccesor = Preprocessor(train_df)\n",
    "preprocessed_df = preproccesor.preprocess()\n",
    "preprocessed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_opts = dict(method='zip', archive_name='out.csv')  \n",
    "preprocessed_df.to_csv('out.zip', index=False, compression=compression_opts)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a get train and test data class\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "class TrainTestData:\n",
    "    def __init__(self, trainDf, testDf) -> None:\n",
    "        self.trainDf = trainDf\n",
    "        self.testDf = testDf\n",
    "\n",
    "    def doSmote(self):\n",
    "        sm = SMOTE()\n",
    "        self.X, self.Y = sm.fit_resample(self.X, self.Y)\n",
    "        return self.trainData, self.testData\n",
    "\n",
    "    def doDecomposition(self):\n",
    "        lsa = TruncatedSVD(n_components=2)\n",
    "        lsa.fit(self.X)\n",
    "        self.trainData = lsa.transform(self.X)\n",
    "        self.testData = lsa.transform(self.testData)\n",
    "        \n",
    "\n",
    "    def get_X(self, minDocumentCount):\n",
    "\n",
    "        # concatinate trainDf and testDf\n",
    "        self.resampling()\n",
    "        self.appendDf = pd.concat(\n",
    "            [self.trainDf[\"comment_text\"], self.testDf[\"comment_text\"]], axis=0\n",
    "        )\n",
    "\n",
    "        token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "        self.vectorizer = CountVectorizer()\n",
    "        #vectorizer = TfidfVectorizer(min_df=5,ngram_range=(1,3),tokenizer=token.tokenize)\n",
    "        # lowercase=True,stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize\n",
    "        self.vectorizer.fit(self.appendDf)\n",
    "\n",
    "        self.trainData = self.vectorizer.transform(self.trainDf[\"comment_text\"])\n",
    "        print(self.trainData.shape)\n",
    "\n",
    "        self.testData = self.vectorizer.transform(self.testDf[\"comment_text\"])\n",
    "        print(self.testData.shape)\n",
    "        self.X = self.trainData\n",
    "\n",
    "        # self.doDecomposition() \n",
    "        return self.X\n",
    "\n",
    "    def resampling(self):\n",
    "        from sklearn.utils import resample\n",
    "        zero_data = self.trainDf[self.trainDf['identity_hate'] == 0]\n",
    "        one_data = self.trainDf[self.trainDf['identity_hate'] == 1]\n",
    "        self.trainDf = pd.concat([resample(zero_data, replace=True, n_samples=len(one_data)*6), one_data])\n",
    "        return self.trainDf\n",
    "\n",
    "    def get_Y(self):\n",
    "        # self.resampling()\n",
    "        self.Y = self.trainDf[\"identity_hate\"]\n",
    "        return self.Y\n",
    "\n",
    "    def testTrainSplit(self):\n",
    "        # self.doSmote()\n",
    "        (\n",
    "            self.X_train,\n",
    "            self.X_test,\n",
    "            self.Y_train,\n",
    "            self.Y_test,\n",
    "        ) = model_selection.train_test_split(\n",
    "            self.X, self.Y, test_size=0.2, random_state=0\n",
    "        )\n",
    "        return self.X_train, self.X_test, self.Y_train, self.Y_test\n",
    "\n",
    "    def get_X_test(self):\n",
    "        return self.testData\n",
    "\n",
    "    def get_X_test_custom(self, df):\n",
    "        return self.vectorizer.transform(df[\"comment_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153164, 2)\n",
      "(9835, 254630)\n",
      "(153164, 254630)\n"
     ]
    }
   ],
   "source": [
    "testPreprocessor = Preprocessor(test_df)\n",
    "preprocessed_test_df = testPreprocessor.preprocess()\n",
    "preprocessed_test_df.head()\n",
    "\n",
    "getTTData = TrainTestData(preprocessed_df, preprocessed_test_df)\n",
    "X = getTTData.get_X(1)\n",
    "y = getTTData.get_Y()\n",
    "X_train, X_test, Y_train, Y_test = getTTData.testTrainSplit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.7, solver='liblinear')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrModel = LogisticRegression(C=0.70,solver=\"liblinear\")\n",
    "lrModel.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1967,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8234362628661915"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_actual = Y_test\n",
    "cv_preds = lrModel.predict(X_test)\n",
    "print(cv_preds.shape)\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "fbeta_score(y_actual, cv_preds, average=\"macro\", beta=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 15.0, 'Predicted label')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUIAAAEGCAYAAAAQZJzmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAd00lEQVR4nO3deZhU1Z3/8fcHWpCoKIuiAlGiqDHGFZeYaFQirhE1mmCMYRRs98Ql4xKdmJjJjOM4MRozRhQUV1x/yiRuCDFqEgTUiKImdlzBBSOLGy7Q398fdRqKtpeqS1VXd9Xn5XMfbp177j2nqMcv59xz7zmKCMzMalm3SlfAzKzSHAjNrOY5EJpZzXMgNLOa50BoZjWvrtIVaIOHs83KT6ty8kdLC///dPW6VSurnDpzIOSjpZWugRVj9Trotd3Jla6GFWHJk5ev0vnV8vRdpw6EZta5RVEdt07bIHQgNLNVUCUtQg+WmFlmUcTWHkkTJM2X9Eyz9FMkPS9pjqSL8tLPkdQg6W+S9slL3zelNUg6u5Dv4RahmWXWWNRNwna7xtcClwPXLT9D2hMYCWwTER9LWi+lbwmMAr4EbAg8KGmzdNpvgL2BucBMSZMj4tm2CnYgNLPsStg1joiHJW3cLPkE4MKI+DjlmZ/SRwKTUvpLkhqAndKxhoh4EUDSpJS3zUDorrGZZVZM11hSvaRZeVt9AUVsBuwm6TFJf5S0Y0ofCLyWl29uSmstvU1uEZpZZsX0jCNiHDCuyCLqgL7ALsCOwK2SvlDkNQoqxMwsk+Ien8lkLnBn5OYLnCGpEegPzAMG5+UblNJoI71V7hqbWWYRhW8Z3QXsCZAGQ3oA/wQmA6Mk9ZQ0BBgKzABmAkMlDZHUg9yAyuT2CnGL0MwyK+WbJZJuBvYA+kuaC5wPTAAmpEdqPgFGp9bhHEm3khsEWQqcFBHL0nVOBu4HugMTImJOu2V34hmqw6/YdS1+xa7rWfLk5av0usc7HywtOID0W6Ou075a4hahmWXWedtRxXEgNLPMqiQOOhCa2SqokkjoQGhmmRX3il3n5UBoZplVRxh0IDSzVVElkdCB0Mwy64A3SzqEA6GZZVYltwgdCM0suyqJgw6EZpZdJ34zrSgOhGaWWZXEQQdCM8uuSuKgA6GZZecWoZnVPD8+Y2ZWHXHQgdDMsmt0IDSzWueusZlZdcRBL95kZtkVs65xeyRNkDQ/rU/S/NgZkkJS//RZki6T1CBptqTt8/KOlvRC2kYX8j0cCM0ssxKvYnctsG/zREmDgRHAq3nJ+5FbuW4oUA9ckfL2Jbfo087ATsD5kvq0V7ADoZllFhEFbwVc62FgQQuHLgHOZOWG5UjgusiZDqwjaQNgH2BKRCyIiIXAFFoIrs05EJpZZsV0jSXVS5qVt9W3d31JI4F5EfFUs0MDgdfyPs9Naa2lt8mDJWaWWTFvlkTEOGBcofklfQ74MblucVm5RWhmmUUR/2WwCTAEeErSy8Ag4AlJ6wPzgMF5eQeltNbS2+RAaGbZlXLYuPmlI56OiPUiYuOI2JhcN3f7iHgTmAx8P40e7wIsjog3gPuBEZL6pEGSESmtTe4am1lmpXyMUNLNwB5Af0lzgfMjYnwr2e8B9gcagA+BowEiYoGknwMzU74LIqKlAZiVOBCaWWalXM4zIo5o5/jGefsBnNRKvgnAhGLKdiA0s+yq5M0SB0Izy6xK4qADoZll54lZzazmefYZM7PqiIMOhGaWnSdmNbOa566xmVl1xEEHQjPLrkrioAOhmWXnx2fMrOYVMuFqV+DZZ0rgJ+edwx67fYVDRx64UvpNN17PyAP35ZCDDuCSiy9a6dgbr7/OLsO2Y+I1K94pv/H6iRw68kAOOegAbrju2o6oujXTs0cdj1z/Ix675Wwev/1czjt+/+XHfnrSN5l910948o7zOPGIr1ewlp1HGSef6VBuEZbAyIMP5Yjvfo9zzzlredqMx6bz0LSp3HbnZHr06ME777yz0jkXX3QhX9ttt+WfX3jh79xx+23cOOk2VlttNU48biy7f31PPr/RRh32PQw+/mQp+9ZfxgdLPqGurhvTJpzOA396ls2HrM+g9ddhm0N+TkSwbp81K13VTqFKGoRuEZbCDsN2pPfaa6+UdtstN3PM2Hp69OgBQL9+/ZYfmzb1QQYOGsgmmw5dnvbSi//gy1tvTa9evairq2OHYTsy9cEHOuYL2Eo+WPIJAKvVdaeurjsRQf3hX+M/xt27vCv49sL3K1nFTqPME7N2mLIFQklbSDorLbl3Wdr/YrnK62xeefllnnh8FkeOOpxjRn+PZ56eDcCHH3zANeOv4vgTTl4p/6abbsYTjz/OokULWbJkCY8+8jBvvvlmJape87p1E9Mnnc2rUy9k2vTnmfnMKwwZtC6HjdiBR288k7suP4FNPr9upavZOVRJ37gsgVDSWcAkQMCMtAm4WdLZbZy3fHGXceMKXtqgU1q6bBmLFy/mhptv5bQzzuRfzziViOCK/72c731/NJ9bY42V8n9hk004esxYjj92DCceN5bNt9iC7t3cYK+ExsZgl1EXsuk+5zFsq43YcpMN6Nmjjo8/+ZSvHXkR19z5Z648/8hKV7NTqJI4WLZ7hGOAL0XEp/mJkn4JzAEubOmkZou7xEdLy1S7DjBgwACGf2NvJPHlrbemW7duLFy4kKdnP8WDD9zPr/7nYt57712kbvTo0ZMjjvweh37rcA791uEAXParXzJgwIAKf4vatvj9Jfxx1t8ZseuWzHtrIXdNzS2kdve0p7jyp9+rcO06h2VVcpOwXE2ORmDDFtI3SMeq3p7Dv8HMGY8B8PLLL/Hpp5/Sp08frr3+Ju6dMo17p0zjyKNGM7b+OI44Mvc/VdOAyhuvv87UBx9gvwO+WbH616r+fdZk7TV7AbB6z9UYvvMW/O3lt/i/h2bz9R1z93R322EoDa/Or2Q1O40SL/BeMeVqEZ4KTJX0AivWGP08sClwcmsndVVn/eh0Zs2cwaJFC9l7r9054aRTOOSQb/GTf/sxh448kNVWW42f/+JCJLV5nTNOPYXFixZRV1fHj887n969e3fQN7Am6/fvzVUXHEX3bt3o1k3cMeUJ7n3kGf785D+45j9Gc8qRe/HBko854YKbKl3VTqGUgyCSJgAHAvMjYquU9t/AN4FPgH8AR0fEonTsHHK9z2XADyLi/pS+L3Ap0B24OiJa7IGuVHa5HoiU1A3YiRWLK88DZkbEsgIv0aW7xrVo9TrotV3V/TtX1ZY8eXnb/zq346G/LSg4gOyxed82y5K0O/A+cF1eIBwBTIuIpZL+CyAizpK0JXAzuRizIfAgsFm61N+BvcmtejcTOCIinm2r7LI9RxgRjcD0cl3fzCqvlC3CiHhY0sbN0vKfIZsOHJb2RwKTIuJj4CVJDeSCIkBDRLwIIGlSyttmIPSwpJllVsw9wvynQtJWX2RxxwD3pv2BrLjtBrnW38A20tvkN0vMLLNiRo2bPRVSFEnnAkuBG7Oc3x4HQjPLrCPeGJH0L+QGUYbHikGNecDgvGyDUhptpLfKXWMzy6zcj8+kEeAzgYMi4sO8Q5OBUZJ6ShoCDCX34sZMYKikIZJ6AKNS3ja5RWhmmZXyoRNJNwN7AP0lzQXOB84BegJT0uNn0yPi+IiYI+lWcoMgS4GTmp5IkXQycD+5x2cmRMSc9sp2IDSzzBpLO2p8RAvJ41tIa8r/C+AXLaTfA9xTTNkOhGaWWWNnf2WkQA6EZpZZlcRBB0Izy66UXeNKciA0s8zcIjSzmlclcdCB0Myyq5ZV7BwIzSyzapmY1YHQzDKrjjDoQGhmq8BdYzOredWy7oYDoZll5hahmdW8KomDDoRmlp1Hjc2s5lVHGHQgNLNVUPX3CCW9x4qA37QMX6T9iAgvumtW46p+1Dgi1urIiphZ11MlDcLCusaSvgYMjYhrJPUH1oqIl8pbNTPr7JY1VkckbHfxJknnA2eRWzsAoAdwQzkrZWZdQ2NEwVt7JE2QNF/SM3lpfSVNkfRC+rNPSpekyyQ1SJotafu8c0an/C9IGl3I9yhkFbtDgIOADwAi4nXA3WYzozEK3wpwLbBvs7SzgakRMRSYmj4D7Edu5bqhQD1wBeQCJ7lFn3YGdgLObwqebSkkEH6S1hKNVNAaBZxjZjWglMt5RsTDwIJmySOBiWl/InBwXvp1kTMdWEfSBsA+wJSIWBARC4EpfDa4fkYhgfBWSVemgo4FHgSuKuA8M6tyjUTBm6R6SbPytvoCihgQEW+k/TeBAWl/IPBaXr65Ka219Da1O1gSERdL2ht4F9gM+ElETGm3+mZW9YoZNY6IccC47GVFSCrL6EyhD1Q/DfQi1z1+uhwVMbOuZ2n5R43fkrRBRLyRur7zU/o8YHBevkEpbR65ReLz0x9qr5BCRo3HAjOAQ4HDgOmSjingC5hZlSvlPcJWTAaaRn5HA3fnpX8/jR7vAixOXej7gRGS+qRBkhEprU2FtAj/FdguIt4BkNQP+DMwoZhvY2bVp5QNQkk3k2vN9Zc0l9zo74XkxinGAK8A307Z7wH2BxqAD4GjASJigaSfAzNTvgsiovkAzGcUEgjfAd7L+/xeSjOzGlfKd40j4ohWDg1vIW8AJ7VynQkU2VBr613j09NuA/CYpLvJ3SMcCcwuphAzq05V8mJJmy3Cpoem/5G2Jne3kNfMalDVz0cYET/ryIqYWddTCy1CACStC5wJfAlYvSk9IvYqY73MrAuokgZhQW+W3Ag8DwwBfga8zIoRGTOrYaWcdKGSCgmE/SJiPPBpRPwxIo4B3Bo0s1JPulAxhTw+82n68w1JBwCvA33LVyUz6yo6eUOvYIUEwn+XtDZwBvBroDdwWllrZWZdQrVMzFrIpAu/S7uLgT3LWx0z60qqfs0SSb+mjdX6IuIHZamRmXUZnX0QpFBttQhndVgtzKxLqpI42OYD1RNbO2ZmBp1/NLhQXuDdzDKr+gXezczas7RKRkscCM0ss6pvEXaGUePVHaa7nCVPXl7pKlgHqpIGYeceNe611y8qXQUrwpJp5/o362KWTDt3lc6v+hahR43NrD1VEgcLnobrLGBLPA2XmeUp9St2kk4DxrJixcyjgQ2ASUA/4HHgqIj4RFJP4DpgB3LLh3wnIl7OUm6h03A9h6fhMrNmIqLgrT2SBgI/AIZFxFZAd2AU8F/AJRGxKbAQGJNOGQMsTOmXpHyZeBouM8usDMt51gG9JNUBnwPeIBdvbk/HJwIHp/2R6TPp+HBJyvI9CgmEK03DJWk7PA2XmVHcxKyS6iXNytvq868VEfOAi4FXyQXAxeS6wosiYmnKNhcYmPYHAq+lc5em/P2yfA9Pw2VmmRVzhzAixgHjWjueFmQfSe423CLgNmDfValfoTwNl5llVuLHZ74BvBQRbwNIuhP4KrCOpLrU6hsEzEv55wGDgbmpK702GddcL2TU+BpaCPzpXqGZ1bASjxq/Cuwi6XPAEnILu88C/gAcRm7keDQrlhSenD7/JR2fFhkjcyFd49/l7a8OHEJuun4zq3GlbBBGxGOSbgeeAJYCT5LrSv8emCTp31Pa+HTKeOB6SQ3AAnIjzJkU0jW+I/+zpJuBR7MWaGbVo9RvlkTE+cD5zZJfBHZqIe9HwOGlKDfL27xDgfVKUbiZdW01Mx+hpPdY+R7hm+TeNDGzGlf17xo3iYi1OqIiZtb1VEcYLOCBaklTC0kzs9qzrDEK3jqztuYjXJ3cKy7904OOTa+u9GbFk91mVsNqoWt8HHAqsCG511yaAuG7gGffNLPqn4YrIi4FLpV0SkT8ugPrZGZdRLWsa1zIpAuNktZp+iCpj6QTy1clM+sqyjD7TEUUEgiPjYhFTR8iYiFwbNlqZGZdRtUPluTpLklN7/BJ6g70KG+1zKwriCp5gKaQQHgfcIukK9Pn41KamdW4zt7lLVQhgfAsoB44IX2eAlxVthqZWZdRLY/PtHuPMCIaI+K3EXFYRBwGPEtuglYzq3GNUfjWmRU06UKanv8I4NvAS8Cd5ayUmXUN1dIibOvNks3IBb8jgH8CtwCKCM9SbWZA6ZfzrJS2WoTPA48AB0ZEAyxfc9TMDKiewZK27hEeSm4lqT9IukrScFa8ZmdmVtJ1jSup1UAYEXdFxChgC3JrBpwKrCfpCkkjOqh+ZtaJ1cybJRHxQUTcFBHfJLeC1JN4YlYzo/QtQknrSLpd0vOSnpP0FUl9JU2R9EL6s0/KK0mXSWqQNFvS9lm/RyGv2C0XEQsjYlxEDM9aoJlVjzK0CC8F7ouILYBtgOeAs4GpETEUmJo+A+xHbumQoeSedb4i6/coKhCameVrbGwseGuPpLWB3Umr1EXEJ2meg5HAxJRtInBw2h8JXBc508mtf7xBlu/hQGhmmRXTIpRUL2lW3lbf7HJDgLeBayQ9KelqSWsAAyLijZTnTWBA2h8IvJZ3/lwyThqdZRU7MzOguAeqI2IcuXWKW1MHbA+cktY4vpQV3eCma4Skkg+9uEVoZpmV+B7hXGBuRDyWPt9OLjC+1dTlTX/OT8fnAYPzzh+U0ormQGhmmZVy1Dgi3gRek7R5ShpObm6DycDolDYauDvtTwa+n0aPdwEW53Whi+KusZll1lj6V+xOAW6U1AN4ETiaXIPtVkljgFfIzXkAcA+wP9AAfJjyZuJAaGaZlfpB6Yj4KzCshUOfeWQvTRZ9UinKdSA0s8w6+6tzhXIgNLPMqiQOOhCaWXZuEZpZzauSOOhAaGbZlWHUuCIcCM0sM3eNzazmORCaWc2rkjjoQGhm2blFaGY1b9kyB0Izq3FV0iD07DOl9tt/PZBX7jiVWeOP/cyxHx6+M0umnUu/3r2Wp/3PySN45voTmHHVWLYdun5HVtWSYn6zUcO/xIyrxjLz6mP5w69H8+UvrNfR1e1Uqn4VO8vm+vufYuTZkz6TPmjdtRg+bAivvrV4edo+O2/CJgP7stVRV3DyL+/hslP37ciqWlLMb/bym4sYcdoN7Dj2Kv7z+kf5zRn7d2RVO52aWcXOivOn2a+x4N0ln0m/6MS9OffKaSv9y3jgrptx05TZAMx47nXWXnN11u+7ZofV1XKK+c2mz5nHovc/AmDGs/MYuG7vDqtnZ+QWoRXswF034/V/vsfTL85fKX3D/msxd/67yz/Pe/tdNuy/VkdXz1rQ2m+W71/234b7H/tHB9aq83GLMCNJrU6emL+4y7hxbS1t0HX06lnHmUfuygXXPlzpqliBCvnNdt92I0bvty3nXTWtA2vW+ZRyFbtKqkSL8GetHUhrJg+LiGH19c0XuOqavrBhHzZafx1mXDWW5286iYHr9uYvV45hQJ81eP2f7zFovRVdq4Hr9ub1f75XwdoatP2bAWz1hfW44kcHcPi/3dZil7qmRBFbJ1aWx2ckzW7tECuW4qsJc156m42+9avln5+/6SS+evwE3nl3Cb//8wscf/Awbp32LDt9cUPe/eBj3lzwfuUqa0Dbv9ng9Xoz6WffYsx/3k3D3AWVq2Qn0dnv/RWqXM8RDgD2ARY2Sxfw5zKV2SlMPO9gdttmI/qv3YuGW07h59c+zMR7n2ox732PNbDPzpsw54YT+fCjTznuot91cG0NivvNzjlqN/r27sWvfrgfAEuXNfK1EyZ0ZHU7lXIEQkndgVnAvIg4UNIQYBLQD3gcOCoiPpHUE7gO2AF4B/hORLycqcwyfZHxwDUR8WgLx26KiO8WcJnotdcvSl43K58l087Fv1nXsmTauVqV8z9/yuSCA8irvz6ooLIknU5u3ZLeKRDeCtwZEZMk/RZ4KiKukHQisHVEHC9pFHBIRHwny/coyz3CiBjTUhBMxwoJgmbWBZT68RlJg4ADgKvTZwF7kVvjGGAicHDaH5k+k44PT/mL5sdnzCyzaIyCt/ynQtLW0ojor4AzgaZh5n7AoohYmj7PBQam/YHAawDp+OKUv2h+19jMMivm1lpEjANafS5O0oHA/Ih4XNIeq1y5IjgQmllmJR5j+CpwkKT9gdWB3sClwDqS6lKrbxAwL+WfBwwG5kqqA9YmN2hSNHeNzSy7Ej5HGBHnRMSgiNgYGAVMi4gjgT8Ah6Vso4G70/7k9Jl0fFpkjMwOhGaWWQe9a3wWcLqkBnL3AMen9PFAv5R+OnB21gLcNTazzMr16lxEPAQ8lPZfBHZqIc9HwOGlKM+B0Mwy85slZmbVEQcdCM0sO7cIzazmORCaWc1zIDSzmheNDoRmVuPcIjSzmudAaGY1z4HQzKw64qADoZll5xahmdW8zr5MZ6EcCM0sM7cIzcyqIw46EJpZdm4RmlnNcyA0M2tcVukalIQDoZllVyUtQq9ZYmbZRWPhWzskDZb0B0nPSpoj6Ycpva+kKZJeSH/2SemSdJmkBkmzJW2f9Ws4EJpZdhGFb+1bCpwREVsCuwAnSdqS3KJMUyNiKDCVFYs07QcMTVs9cEXWr+FAaGbZlbBFGBFvRMQTaf894DlgIDASmJiyTQQOTvsjgesiZzq59Y83yPI1HAjNLLsiAqGkekmz8rb61i4raWNgO+AxYEBEvJEOvQkMSPsDgdfyTpub0ormwRIzy66IUeOIGAeMay+fpDWBO4BTI+JdSfnXCEklH6Fxi9DMsivtPUIkrUYuCN4YEXem5Leaurzpz/kpfR4wOO/0QSmtaA6EZpZdaUeNBYwHnouIX+YdmgyMTvujgbvz0r+fRo93ARbndaGL4q6xmWVX2ucIvwocBTwt6a8p7cfAhcCtksYArwDfTsfuAfYHGoAPgaOzFuxAaGbZFdDSK/hSEY8CauXw8BbyB3BSKcp2IDSz7KrkzRIHQjPLzu8am1nNK2HXuJIcCM0sOy/wbmY1zy1CM6t5DoRmVvM8WGJmNc+Pz5hZzXPX2MxqnluEZlbz3CI0s5rnFqGZ1TyPGptZzXPX2MxqnrvGZlbzqqRFqKiSiN6VSKpPC9lYF+Dfq/p5zZLKaHUZQ+uU/HtVOQdCM6t5DoRmVvMcCCvD95u6Fv9eVc6DJWZW89wiNLOa50BoZjXPgbADSdpX0t8kNUg6u9L1sbZJmiBpvqRnKl0XKy8Hwg4iqTvwG2A/YEvgCElbVrZW1o5rgX0rXQkrPwfCjrMT0BARL0bEJ8AkYGSF62RtiIiHgQWVroeVnwNhxxkIvJb3eW5KM7MKcyA0s5rnQNhx5gGD8z4PSmlmVmEOhB1nJjBU0hBJPYBRwOQK18nMcCDsMBGxFDgZuB94Drg1IuZUtlbWFkk3A38BNpc0V9KYStfJysOv2JlZzXOL0MxqngOhmdU8B0Izq3kOhGZW8xwIzazmORB2YZKWSfqrpGck3Sbpc6twrWslHZb2r25rQghJe0jaNUMZL0vqX2h6szzvF1nWTyX9qNg6Wm1yIOzalkTEthGxFfAJcHz+QUmZ1q2OiLER8WwbWfYAig6EZp2VA2H1eATYNLXWHpE0GXhWUndJ/y1ppqTZko4DUM7laX7EB4H1mi4k6SFJw9L+vpKekPSUpKmSNiYXcE9LrdHdJK0r6Y5UxkxJX03n9pP0gKQ5kq4G1N6XkHSXpMfTOfXNjl2S0qdKWjelbSLpvnTOI5K2KMnfptWUTC0G61xSy28/4L6UtD2wVUS8lILJ4ojYUVJP4E+SHgC2AzYnNzfiAOBZYEKz664LXAXsnq7VNyIWSPot8H5EXJzy3QRcEhGPSvo8ubdnvgicDzwaERdIOgAo5M2MY1IZvYCZku6IiHeANYBZEXGapJ+ka59MbmGl4yPiBUk7A/8L7JXhr9FqmANh19ZL0l/T/iPAeHJd1hkR8VJKHwFs3XT/D1gbGArsDtwcEcuA1yVNa+H6uwAPN10rIlqbm+8bwJbS8gZfb0lrpjIOTef+XtLCAr7TDyQdkvYHp7q+AzQCt6T0G4A7Uxm7Arflld2zgDLMVuJA2LUtiYht8xNSQPggPwk4JSLub5Zv/xLWoxuwS0R81EJdCiZpD3JB9SsR8aGkh4DVW8keqdxFzf8OzIrle4TV737gBEmrAUjaTNIawMPAd9I9xA2APVs4dzqwu6Qh6dy+Kf09YK28fA8ApzR9kLRt2n0Y+G5K2w/o005d1wYWpiC4BbkWaZNuQFOr9rvkutzvAi9JOjyVIUnbtFOG2Wc4EFa/q8nd/3siLUJ0JbmewP8DXkjHriM3y8pKIuJtoJ5cN/QpVnRN/w84pGmwBPgBMCwNxjzLitHrn5ELpHPIdZFfbaeu9wF1kp4DLiQXiJt8AOyUvsNewAUp/UhgTKrfHLz8gWXg2WfMrOa5RWhmNc+B0MxqngOhmdU8B0Izq3kOhGZW8xwIzazmORCaWc37//stnn4rrnEJAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use sns to plot the confusion matrix\n",
    "cm = confusion_matrix(y_actual, cv_preds)\n",
    "sns.heatmap(cm, annot=True, fmt=\".0f\", linewidths=0.5, square=True, cmap=\"Blues_r\")\n",
    "plt.ylabel(\"Actual label\")\n",
    "plt.xlabel(\"Predicted label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sup, Gay piece of shit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hello there</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I don't like gays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fuck off faggot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I am dhanush</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             comment_text\n",
       "0  Sup, Gay piece of shit\n",
       "1             Hello there\n",
       "2       I don't like gays\n",
       "3         Fuck off faggot\n",
       "4            I am dhanush"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_dict = {\"comment_text\":[\"Sup, Gay piece of shit\", \"Hello there\", \"I don't like gays\", \"Fuck off faggot\", \"I am dhanush\"]}\n",
    "check_df = pd.DataFrame(check_dict) \n",
    "check_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubmissionPipeline:\n",
    "    def __init__(self, testDf, model,testTrainData):\n",
    "        self.testDf = testDf\n",
    "        self.model = model\n",
    "        self.getTTData = testTrainData\n",
    "\n",
    "    def run(self):\n",
    "        self.predictions = self.model.predict(getTTData.get_X_test_custom(self.testDf))\n",
    "        self.submission_df = pd.DataFrame({\"target\": self.predictions})\n",
    "        print(self.submission_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   target\n",
      "0       1\n",
      "1       0\n",
      "2       0\n",
      "3       1\n",
      "4       0\n"
     ]
    }
   ],
   "source": [
    "submissionPipeline = SubmissionPipeline(check_df, lrModel, getTTData)\n",
    "submissionPipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
