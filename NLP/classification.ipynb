{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ml packages\n",
    "\n",
    "import string\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn.model_selection as model_selection\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import (CountVectorizer, HashingVectorizer, TfidfVectorizer)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.decomposition import PCA, TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  identity_hate\n",
       "0  Explanation\\nWhy the edits made under my usern...              0\n",
       "1  D'aww! He matches this background colour I'm s...              0\n",
       "2  Hey man, I'm really not trying to edit war. It...              0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...              0\n",
       "4  You, sir, are my hero. Any chance you remember...              0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"../data/trimmed.csv\")\n",
    "test_df = pd.read_csv(\"../data/test_trimmed.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a preprocessing class\n",
    "class Preprocessor:\n",
    "    def __init__(self, df) -> None:\n",
    "        self.df = df\n",
    "\n",
    "    # convert all charecters to lower case\n",
    "    def convertToLower(self):\n",
    "        self.df[\"comment_text\"] = self.df[\"comment_text\"].apply(lambda x: x.lower())\n",
    "        return self.df\n",
    "\n",
    "    # remove stop words\n",
    "    def removeStopWords(self):\n",
    "        stop = stopwords.words(\"english\")\n",
    "        self.df[\"comment_text\"] = self.df[\"comment_text\"].apply(\n",
    "            lambda x: \" \".join([word for word in x.split() if word not in stop])\n",
    "        )\n",
    "        return self.df\n",
    "\n",
    "    # remove punctuation\n",
    "    def removePunctuation(self):\n",
    "        self.df[\"comment_text\"] = self.df[\"comment_text\"].str.replace(\"[^\\w\\s]\", \"\")\n",
    "        return self.df\n",
    "\n",
    "    # remove numbers\n",
    "    def removeNumbers(self):\n",
    "        self.df[\"comment_text\"] = self.df[\"comment_text\"].str.replace(\"[0-9]\", \"\")\n",
    "        return self.df\n",
    "\n",
    "    # remove whitespaces\n",
    "    def removeWhitespaces(self):\n",
    "        self.df[\"comment_text\"] = self.df[\"comment_text\"].apply(\n",
    "            lambda x: \" \".join(x.split())\n",
    "        )\n",
    "        return self.df\n",
    "\n",
    "    # remove urls\n",
    "    def removeURLs(self):\n",
    "        self.df[\"comment_text\"] = self.df[\"comment_text\"].str.replace(\n",
    "            \"https?://\\S+|www\\.\\S+\", \"\"\n",
    "        )\n",
    "        return self.df\n",
    "\n",
    "    # snowball stemmer algorithm\n",
    "    def snowballstemmer(self):\n",
    "        stemmer = SnowballStemmer()\n",
    "\n",
    "        def stem_words(text):\n",
    "            return \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "\n",
    "        self.df[\"comment_text\"] = self.df[\"comment_text\"].apply(\n",
    "            lambda x: stem_words(x)\n",
    "        )\n",
    "        return self.df\n",
    "\n",
    "    # port stemmer algorithm\n",
    "    def porterstemmer(self):\n",
    "        stemmer = PorterStemmer()\n",
    "\n",
    "        def stem_words(text):\n",
    "            return \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "\n",
    "        self.df[\"comment_text\"] = self.df[\"comment_text\"].apply(\n",
    "            lambda x: stem_words(x)\n",
    "        )\n",
    "        return self.df\n",
    "\n",
    "    # lemmatizing\n",
    "    def lemmatize(self):\n",
    "        from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "        def lemmatize_words(text):\n",
    "            return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "\n",
    "        self.df[\"comment_text\"] = self.df[\"comment_text\"].apply(\n",
    "            lambda x: lemmatize_words(x)\n",
    "        )\n",
    "        return self.df\n",
    "\n",
    "    # remove id and index columns\n",
    "    def removeUnwantedCols(self, col):\n",
    "        print(self.df.shape)\n",
    "        self.df = self.df.drop(col, axis=1)\n",
    "        return self.df\n",
    "\n",
    "    # word tokenization using nltk\n",
    "    def wordTokenization(self):\n",
    "        self.df[\"comment_text\"] = self.df[\"comment_text\"].apply(\n",
    "            lambda x: nltk.word_tokenize(x)\n",
    "        )\n",
    "        return self.df\n",
    "        \n",
    "\n",
    "    def preprocess(self):\n",
    "        self.df = self.convertToLower()\n",
    "        self.df = self.removeStopWords()\n",
    "        self.df = self.removePunctuation()\n",
    "        self.df = self.removeNumbers()\n",
    "        self.df = self.removeURLs()\n",
    "        self.df = self.removeWhitespaces()\n",
    "        # self.df = self.snowballstemmer()\n",
    "        # self.df = self.porterstemmer()\n",
    "        # self.df = self.lemmatize()\n",
    "        # self.df = self.wordTokenization()\n",
    "\n",
    "        # print(self.df.head())\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_95321/2632918769.py:21: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df[\"comment_text\"] = self.df[\"comment_text\"].str.replace(\"[^\\w\\s]\", \"\")\n",
      "/tmp/ipykernel_95321/2632918769.py:26: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df[\"comment_text\"] = self.df[\"comment_text\"].str.replace(\"[0-9]\", \"\")\n",
      "/tmp/ipykernel_95321/2632918769.py:38: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df[\"comment_text\"] = self.df[\"comment_text\"].str.replace(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>daww matches background colour im seemingly st...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man im really trying edit war guy constant...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cant make real suggestions improvement wondere...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you sir hero chance remember page thats on</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  identity_hate\n",
       "0  explanation edits made username hardcore metal...              0\n",
       "1  daww matches background colour im seemingly st...              0\n",
       "2  hey man im really trying edit war guy constant...              0\n",
       "3  cant make real suggestions improvement wondere...              0\n",
       "4         you sir hero chance remember page thats on              0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproccesor = Preprocessor(train_df)\n",
    "preprocessed_df = preproccesor.preprocess()\n",
    "preprocessed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_opts = dict(method='zip', archive_name='out.csv')  \n",
    "preprocessed_df.to_csv('out.zip', index=False, compression=compression_opts)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a get train and test data class\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "class TrainTestData:\n",
    "    def __init__(self, trainDf, testDf) -> None:\n",
    "        self.trainDf = trainDf\n",
    "        self.testDf = testDf\n",
    "\n",
    "    def doSmote(self):\n",
    "        sm = SMOTE()\n",
    "        self.X, self.Y = sm.fit_resample(self.X, self.Y)\n",
    "        return self.trainData, self.testData\n",
    "\n",
    "    def doDecomposition(self):\n",
    "        lsa = TruncatedSVD(n_components=2)\n",
    "        lsa.fit(self.X)\n",
    "        self.trainData = lsa.transform(self.X)\n",
    "        self.testData = lsa.transform(self.testData)\n",
    "        \n",
    "\n",
    "    def get_X(self, minDocumentCount):\n",
    "\n",
    "        # concatinate trainDf and testDf\n",
    "        self.resampling()\n",
    "        self.appendDf = pd.concat(\n",
    "            [self.trainDf[\"comment_text\"], self.testDf[\"comment_text\"]], axis=0\n",
    "        )\n",
    "\n",
    "        token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "        self.vectorizer = CountVectorizer()\n",
    "        #vectorizer = TfidfVectorizer(min_df=5,ngram_range=(1,3),tokenizer=token.tokenize)\n",
    "        # lowercase=True,stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize\n",
    "        self.vectorizer.fit(self.appendDf)\n",
    "\n",
    "        self.trainData = self.vectorizer.transform(self.trainDf[\"comment_text\"])\n",
    "        print(self.trainData.shape)\n",
    "\n",
    "        self.testData = self.vectorizer.transform(self.testDf[\"comment_text\"])\n",
    "        print(self.testData.shape)\n",
    "        self.X = self.trainData\n",
    "\n",
    "        # self.doDecomposition() \n",
    "        return self.X\n",
    "\n",
    "    def resampling(self):\n",
    "        from sklearn.utils import resample\n",
    "        zero_data = self.trainDf[self.trainDf['identity_hate'] == 0]\n",
    "        one_data = self.trainDf[self.trainDf['identity_hate'] == 1]\n",
    "        self.trainDf = pd.concat([resample(zero_data, replace=True, n_samples=len(one_data)*6), one_data])\n",
    "        return self.trainDf\n",
    "\n",
    "    def get_Y(self):\n",
    "        # self.resampling()\n",
    "        self.Y = self.trainDf[\"identity_hate\"]\n",
    "        return self.Y\n",
    "\n",
    "    def testTrainSplit(self):\n",
    "        # self.doSmote()\n",
    "        (\n",
    "            self.X_train,\n",
    "            self.X_test,\n",
    "            self.Y_train,\n",
    "            self.Y_test,\n",
    "        ) = model_selection.train_test_split(\n",
    "            self.X, self.Y, test_size=0.2, random_state=0\n",
    "        )\n",
    "        return self.X_train, self.X_test, self.Y_train, self.Y_test\n",
    "\n",
    "    def get_X_test(self):\n",
    "        return self.testData\n",
    "\n",
    "    def get_X_test_custom(self, df):\n",
    "        return self.vectorizer.transform(df[\"comment_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_95321/2632918769.py:21: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df[\"comment_text\"] = self.df[\"comment_text\"].str.replace(\"[^\\w\\s]\", \"\")\n",
      "/tmp/ipykernel_95321/2632918769.py:26: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df[\"comment_text\"] = self.df[\"comment_text\"].str.replace(\"[0-9]\", \"\")\n",
      "/tmp/ipykernel_95321/2632918769.py:38: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  self.df[\"comment_text\"] = self.df[\"comment_text\"].str.replace(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9835, 293063)\n",
      "(153164, 293063)\n"
     ]
    }
   ],
   "source": [
    "testPreprocessor = Preprocessor(test_df)\n",
    "preprocessed_test_df = testPreprocessor.preprocess()\n",
    "preprocessed_test_df.head()\n",
    "\n",
    "getTTData = TrainTestData(preprocessed_df, preprocessed_test_df)\n",
    "X = getTTData.get_X(1)\n",
    "y = getTTData.get_Y()\n",
    "X_train, X_test, Y_train, Y_test = getTTData.testTrainSplit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.7, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.7, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.7, solver='liblinear')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrModel = LogisticRegression(C=0.70,solver=\"liblinear\")\n",
    "lrModel.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1967,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8735187218091011"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_actual = Y_test\n",
    "cv_preds = lrModel.predict(X_test)\n",
    "print(cv_preds.shape)\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "fbeta_score(y_actual, cv_preds, average=\"macro\", beta=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sup, Gay piece of shit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hello there</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I don't like gays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fuck off faggot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I am Groot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             comment_text\n",
       "0  Sup, Gay piece of shit\n",
       "1             Hello there\n",
       "2       I don't like gays\n",
       "3         Fuck off faggot\n",
       "4              I am Groot"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_dict = {\"comment_text\":[\"Sup, Gay piece of shit\", \"Hello there\", \"I don't like gays\", \"Fuck off faggot\", \"I am Groot\"]}\n",
    "check_df = pd.DataFrame(check_dict) \n",
    "check_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubmissionPipeline:\n",
    "    def __init__(self, testDf, model,testTrainData):\n",
    "        self.testDf = testDf\n",
    "        self.model = model\n",
    "        self.getTTData = testTrainData\n",
    "\n",
    "    def run(self):\n",
    "        self.predictions = self.model.predict(getTTData.get_X_test_custom(self.testDf))\n",
    "        self.submission_df = pd.DataFrame({\"target\": self.predictions})\n",
    "        print(self.submission_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   target\n",
      "0       1\n",
      "1       0\n",
      "2       0\n",
      "3       1\n",
      "4       0\n"
     ]
    }
   ],
   "source": [
    "submissionPipeline = SubmissionPipeline(check_df, lrModel, getTTData)\n",
    "submissionPipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "!mkdir ../data/models\n",
    "\n",
    "\n",
    "with open(\"../data/models/lr.pkl\", \"wb\") as f:\n",
    "    pickle.dump(lrModel, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
